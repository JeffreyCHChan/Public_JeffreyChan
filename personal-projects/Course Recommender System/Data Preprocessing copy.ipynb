{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Course Recommendation System</h1>\n",
    "\n",
    "Data provided by Concordia Open Data, files used last updated May 30 2023\n",
    "\n",
    "catalog is the dataset that contains the course description <br>\n",
    "sr is the default dataset that we will join on to obtain the final \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Sniffer to infer the delimiter of the CSV file\n",
    "with open('CATALOG.csv', 'r') as file:\n",
    "    dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "    delimiter = dialect.delimiter\n",
    "\n",
    "# Read the CSV file using pandas with the inferred delimiter\n",
    "catalog = pd.read_csv('CATALOG.csv', delimiter=delimiter)\n",
    "catalog = catalog.drop([ \"Website\",'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15',\n",
    "       'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19',\n",
    "       'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23'], axis=1)\n",
    "# Access the column containing potential commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = pd.read_csv(\"CU_SR_OPEN_DATA_CATALOG.csv\", encoding=\"utf_16_le\")\n",
    "sr = sr.drop([\"Career\"], axis=1)\n",
    "# comb = pd.read_csv(\"CU_SR_OPEN_DATA_COMB_SECTIONS.csv\", encoding=\"utf_16_le\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog.columns\n",
    "catalog[\"Subject_Catalog\"] = catalog[\"Course code\"] +\"_\"+ catalog[\"Course number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr.columns\n",
    "sr[\"Subject_Catalog\"] = sr[\"Subject\"] +\"_\"+ sr[\"Catalog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sr.merge(catalog, on=\"Subject_Catalog\")\n",
    "dataset = dataset.drop([\"Course code\", \"Course number\", \"Component Code\", \"Key\", \"Course ID\", \"Title\"], axis=1)\n",
    "dataset = dataset.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creation of Catalog Catagories </h1>\n",
    "\n",
    "(ex: 200-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returned as str instead of int for the sake of concatenation\n",
    "def fun1(x):\n",
    "    x = re.findall(r'\\d+',x)[0]\n",
    "    if int(x)<1000:\n",
    "        return str((int(x)//100)*100)\n",
    "    elif int(x)>=1000:\n",
    "        return str((int(x)//1000)*10000)\n",
    "\n",
    "dataset['Level'] = dataset['Catalog'].map(lambda x:fun1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Categorical Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        1605\n",
       "ELEC 372 = ENGR 372        6\n",
       "COEN 312 = COEN 212        6\n",
       "COEN 421 = SOEN 422        5\n",
       "AHSC538 = AHSC536          4\n",
       "                        ... \n",
       "DFTT 211 = DFTT 298C       1\n",
       "DFTT 211=SCEN 214          1\n",
       "DFTT 341=SCEN 344          1\n",
       "DFTT 470=SCEN 470          1\n",
       "TESL471 = TESL498A         1\n",
       "Name: Equivalent Courses, Length: 234, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Degree\"].value_counts()\n",
    "dataset[\"Pre Requisite Description\"].value_counts()\n",
    "dataset[\"Equivalent Courses\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Removing Stop Words & Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enStop = stopwords.words('english')\n",
    "frStop = stopwords.words('french')\n",
    "dataset['Description_without_stopwords'] = dataset['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (enStop) and word not in (frStop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Changes:\n",
    "\"Catalog\" removed; \"Level\" added \n",
    "\"Subject_Catalog\" removed; \"Subject\" added\n",
    "'''\n",
    "\n",
    "dataset[\"Encoding\"] = dataset[\"Long Title\"]+ \" \" + dataset[\"Equivalent Courses\"] + \" \" + dataset[\"Faculty\"] + \" \" + dataset[\"Department\"] + \" \" + dataset[\"Subject\"] +\" \"+ dataset[\"Catalog\"] +\" \"+ dataset[\"Level\"] + \" \" + dataset[\"Degree\"] + \" \" + dataset[\"Description_without_stopwords\"]\n",
    "\n",
    "dataset[\"Encoding\"].to_csv(\"Encoding.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13809f5fbb2c71687ac0fbc02129e4c89f53832ed2f3a101566dd09001991f6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
